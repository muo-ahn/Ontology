# ==========================================
# ğŸ§  Ontology Ã— vLM Ã— LLM Prototype
# Makefile (Local / GPU / Metal ê³µìš©)
# ==========================================

PROJECT_NAME = grounded-ai
OLLAMA_HOST = http://localhost:11434
NEO4J_URI = bolt://neo4j:7687
NEO4J_USER = neo4j
NEO4J_PASS = test1234
QDRANT_URL = http://qdrant:6333

# ------------------------------------------
# ê¸°ë³¸ ëª…ë ¹
# ------------------------------------------
.PHONY: up down rebuild logs seed pull models clean

## ì»¨í…Œì´ë„ˆ ê¸°ë™ (FastAPI, Neo4j, Qdrant, UI)
up:
	@echo "ğŸš€ Starting $(PROJECT_NAME) stack..."
	OLLAMA_HOST=$(OLLAMA_HOST) docker compose up -d --build

## ì»¨í…Œì´ë„ˆ ì¢…ë£Œ
down:
	@echo "ğŸ§¹ Stopping containers..."
	docker compose down -v

## ì „ì²´ ì¬ë¹Œë“œ
rebuild: down up

## ì‹¤ì‹œê°„ ë¡œê·¸ ë³´ê¸° (APIë§Œ)
logs:
	docker compose logs -f api

## ì‹œë“œ ë°ì´í„° ì£¼ì… (Neo4j)
seed:
	@echo "ğŸŒ± Seeding Neo4j with sample Ontology..."
	cypher-shell -a $(NEO4J_URI) -u $(NEO4J_USER) -p $(NEO4J_PASS) -f /data/seed.cypher || true

## ë¶ˆëŸ¬ì˜¤ê¸° (Ollama ëª¨ë¸)
pull:
	@echo "â¬‡ï¸ Pulling base models from Ollama..."
	ollama pull qwen2.5:7b-instruct-q4_K_M
# 	ollama pull qwen2-vl:2b-instruct-q4_0
# 	ollama pull minicpm-v:2_6

## ë¡œì»¬ ëª¨ë¸ í´ë” ì¤€ë¹„
models:
	mkdir -p ./models ./data ./ui ./api

## ì •ë¦¬
clean:
	@echo "ğŸ§½ Cleaning build artifacts..."
	docker system prune -f
	rm -rf ./__pycache__ */__pycache__ .pytest_cache || true

# ------------------------------------------
# ìœ í‹¸ë¦¬í‹°
# ------------------------------------------

## FastAPI API í¬íŠ¸ í™•ì¸
status:
	@echo "ğŸŒ API endpoint: http://localhost:8000"
	@echo "ğŸ“Š Streamlit UI: http://localhost:8501"
	@echo "ğŸ§© Neo4j Browser: http://localhost:7474"
	@echo "ğŸ’¾ Qdrant Dashboard: http://localhost:6333/dashboard"

## Neo4j ì½˜ì†” ì ‘ì†
neo4j:
	docker exec -it $$(docker ps -qf "name=neo4j") cypher-shell -u $(NEO4J_USER) -p $(NEO4J_PASS)

## GPU ëª¨ë“œ ì‹¤í–‰ (4070 ë“±)
gpu:
	@echo "âš¡ Starting with GPU profile..."
	OLLAMA_HOST=$(OLLAMA_HOST) docker compose --profile gpu up -d --build

# ------------------------------------------
# ê¸°ë³¸ íë¦„ (ì›í´ë¦­)
# ------------------------------------------

## ì „ì²´ ì´ˆê¸°í™” & ì‹¤í–‰
init: models pull up seed status
	@echo "âœ… Initialization complete!"
